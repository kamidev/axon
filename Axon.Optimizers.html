<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="ExDoc v0.29.1">
    <meta name="project" content="Axon v0.3.0">

    <title>Axon.Optimizers â€” Axon v0.3.0</title>
    <link rel="stylesheet" href="dist/html-elixir-V2ETBPMB.css" />


    <script src="dist/handlebars.runtime-NWIB6V2M.js"></script>
    <script src="dist/handlebars.templates-IV5W3OL2.js"></script>
    <script src="dist/sidebar_items-3818941C.js"></script>

      <script src="docs_config.js"></script>

    <script async src="dist/html-XN2TSG4M.js"></script>


  </head>
  <body data-type="modules" class="page-module">
    <script>

      try {
        var settings = JSON.parse(localStorage.getItem('ex_doc:settings') || '{}');

        if (settings.theme === 'dark' ||
           ((settings.theme === 'system' || settings.theme == null) &&
             window.matchMedia('(prefers-color-scheme: dark)').matches)
           ) {
          document.body.classList.add('dark')
        }
      } catch (error) { }
    </script>

<div class="main">

<button class="sidebar-button sidebar-toggle" aria-label="toggle sidebar">
  <i class="ri-menu-line ri-lg" title="Collapse/expand sidebar"></i>
</button>

<section class="sidebar">
  <form class="sidebar-search" action="search.html">
    <button type="submit" class="search-button" aria-label="Submit Search">
      <i class="ri-search-2-line" aria-hidden="true" title="Submit search"></i>
    </button>
    <button type="button" tabindex="-1" class="search-close-button" aria-label="Cancel Search">
      <i class="ri-close-line ri-lg" aria-hidden="true" title="Cancel search"></i>
    </button>
    <label class="search-label">
      <p class="sr-only">Search</p>
      <input name="q" type="text" class="search-input" placeholder="Search..." aria-label="Input your search terms" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" />
    </label>
  </form>

  <div class="autocomplete">
    <div class="autocomplete-results">
    </div>
  </div>

  <div class="sidebar-header">

      <a href="Axon.html">
        <img src="assets/logo.png" alt="Axon" class="sidebar-projectImage">
      </a>

    <div class="sidebar-projectDetails">
      <a href="Axon.html" class="sidebar-projectName" translate="no">
Axon
      </a>
      <strong class="sidebar-projectVersion" translate="no">
        v0.3.0
      </strong>
    </div>
    <ul class="sidebar-listNav">
      <li><a id="extras-list-link" href="#full-list">Pages</a></li>

        <li><a id="modules-list-link" href="#full-list">Modules</a></li>


    </ul>
  </div>

  <div class="gradient"></div>
  <ul id="full-list" class="sidebar-fullList"></ul>
</section>

<section class="content">
  <output role="status" id="toast"></output>
  <div class="content-outer">
    <div id="content" class="content-inner">

<h1>
<button class="icon-action display-settings">
  <i class="ri-settings-3-line"></i>
  <span class="sr-only">Settings</span>
</button>


    <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L1" title="View Source" class="icon-action" rel="help">
      <i class="ri-code-s-slash-line" aria-hidden="true"></i>
      <span class="sr-only">View Source</span>
    </a>

  <span translate="no">Axon.Optimizers</span> 
  <small class="app-vsn" translate="no">(Axon v0.3.0)</small>

</h1>


  <section id="moduledoc">
<p>Implementations of common gradient-based optimization algorithms.</p><p>All of the methods in this module are written in terms of
the update methods defined in <a href="Axon.Updates.html"><code class="inline">Axon.Updates</code></a>. Axon treats
optimizers as the tuple:</p><pre><code class="makeup elixir" translate="no"><span class="p" data-group-id="8899960899-1">{</span><span class="n">init_fn</span><span class="p">,</span><span class="w"> </span><span class="n">update_fn</span><span class="p" data-group-id="8899960899-1">}</span></code></pre><p>where <code class="inline">init_fn</code> returns an initial optimizer state and <code class="inline">update_fn</code>
scales input gradients. <code class="inline">init_fn</code> accepts a model's parameters
and attaches state to each parameter. <code class="inline">update_fn</code> accepts
gradients, optimizer state, and current model parameters and
returns updated optimizer state and gradients.</p><p>Custom optimizers are often created via the <a href="Axon.Updates.html"><code class="inline">Axon.Updates</code></a> API.</p><h2 id="module-example" class="section-heading">
  <a href="#module-example" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">example</p>
  </a>
  Example
</h2>
<p>Consider the following usage of the Adam optimizer in a basic
update function (assuming <code class="inline">objective</code> and the <code class="inline">dataset</code> are
defined elsewhere):</p><pre><code class="makeup elixir" translate="no"><span class="kd">defmodule</span><span class="w"> </span><span class="nc">Learning</span><span class="w"> </span><span class="k" data-group-id="3511026097-1">do</span><span class="w">

  </span><span class="kn">import</span><span class="w"> </span><span class="nc">Nx.Defn</span><span class="w">

  </span><span class="kd">defn</span><span class="w"> </span><span class="nf">init</span><span class="p" data-group-id="3511026097-2">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">init_fn</span><span class="p" data-group-id="3511026097-2">)</span><span class="w"> </span><span class="k" data-group-id="3511026097-3">do</span><span class="w">
    </span><span class="n">init_fn</span><span class="o">.</span><span class="p" data-group-id="3511026097-4">(</span><span class="n">params</span><span class="p" data-group-id="3511026097-4">)</span><span class="w">
  </span><span class="k" data-group-id="3511026097-3">end</span><span class="w">

  </span><span class="kd">defn</span><span class="w"> </span><span class="nf">update</span><span class="p" data-group-id="3511026097-5">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">optimizer_state</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p">,</span><span class="w"> </span><span class="n">update_fn</span><span class="p" data-group-id="3511026097-5">)</span><span class="w"> </span><span class="k" data-group-id="3511026097-6">do</span><span class="w">
    </span><span class="p" data-group-id="3511026097-7">{</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">gradient</span><span class="p" data-group-id="3511026097-7">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value_and_grad</span><span class="p" data-group-id="3511026097-8">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">objective</span><span class="p" data-group-id="3511026097-9">(</span><span class="ni">&amp;1</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p" data-group-id="3511026097-9">)</span><span class="p" data-group-id="3511026097-8">)</span><span class="w">
    </span><span class="p" data-group-id="3511026097-10">{</span><span class="n">scaled_updates</span><span class="p">,</span><span class="w"> </span><span class="n">new_optimizer_state</span><span class="p" data-group-id="3511026097-10">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">update_fn</span><span class="o">.</span><span class="p" data-group-id="3511026097-11">(</span><span class="n">gradient</span><span class="p">,</span><span class="w"> </span><span class="n">optimizer_state</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="p" data-group-id="3511026097-11">)</span><span class="w">
    </span><span class="p" data-group-id="3511026097-12">{</span><span class="nc">Axon.Updates</span><span class="o">.</span><span class="n">apply_updates</span><span class="p" data-group-id="3511026097-13">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">scaled_updates</span><span class="p" data-group-id="3511026097-13">)</span><span class="p">,</span><span class="w"> </span><span class="n">new_optimizer_state</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p" data-group-id="3511026097-12">}</span><span class="w">
  </span><span class="k" data-group-id="3511026097-6">end</span><span class="w">
</span><span class="k" data-group-id="3511026097-1">end</span><span class="w">

</span><span class="n">model_params</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Nx</span><span class="o">.</span><span class="n">random_uniform</span><span class="p" data-group-id="3511026097-14">(</span><span class="p" data-group-id="3511026097-15">{</span><span class="mi">784</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p" data-group-id="3511026097-15">}</span><span class="p" data-group-id="3511026097-14">)</span><span class="w">
</span><span class="p" data-group-id="3511026097-16">{</span><span class="n">init_fn</span><span class="p">,</span><span class="w"> </span><span class="n">update_fn</span><span class="p" data-group-id="3511026097-16">}</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Axon.Optimizers</span><span class="o">.</span><span class="n">adam</span><span class="p" data-group-id="3511026097-17">(</span><span class="mf">0.005</span><span class="p" data-group-id="3511026097-17">)</span><span class="w">

</span><span class="n">optimizer_state</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="nc">Learning</span><span class="o">.</span><span class="n">init</span><span class="p" data-group-id="3511026097-18">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">init_fn</span><span class="p" data-group-id="3511026097-18">)</span><span class="w">

</span><span class="p" data-group-id="3511026097-19">{</span><span class="n">new_params</span><span class="p">,</span><span class="w"> </span><span class="n">new_optimizer_state</span><span class="p">,</span><span class="w"> </span><span class="n">loss</span><span class="p" data-group-id="3511026097-19">}</span><span class="w"> </span><span class="o">=</span><span class="w">
  </span><span class="nc">Learning</span><span class="o">.</span><span class="n">update</span><span class="p" data-group-id="3511026097-20">(</span><span class="n">params</span><span class="p">,</span><span class="w"> </span><span class="n">optimizer_state</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">targets</span><span class="p">,</span><span class="w"> </span><span class="n">update_fn</span><span class="p" data-group-id="3511026097-20">)</span></code></pre><p>For a simpler approach, you can also use optimizers with the training API:</p><pre><code class="makeup elixir" translate="no"><span class="w">  </span><span class="n">model</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">trainer</span><span class="p" data-group-id="8605809298-1">(</span><span class="ss">:categorical_cross_entropy</span><span class="p">,</span><span class="w"> </span><span class="nc">Axon.Optimizers</span><span class="o">.</span><span class="n">adam</span><span class="p" data-group-id="8605809298-2">(</span><span class="mf">0.005</span><span class="p" data-group-id="8605809298-2">)</span><span class="p" data-group-id="8605809298-1">)</span><span class="w">
  </span><span class="o">|&gt;</span><span class="w"> </span><span class="nc">Axon.Loop</span><span class="o">.</span><span class="n">run</span><span class="p" data-group-id="8605809298-3">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="ss">epochs</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="ss">compiler</span><span class="p">:</span><span class="w"> </span><span class="nc">EXLA</span><span class="p" data-group-id="8605809298-3">)</span></code></pre>
  </section>


  <section id="summary" class="details-list">
    <h1 class="section-heading">
      <a class="hover-link" href="#summary">
        <i class="ri-link-m" aria-hidden="true"></i>
        <span class="sr-only">Link to this section</span>
      </a>
      Summary
    </h1>
<div class="summary-functions summary">
  <h2>
    <a href="#functions">Functions</a>
  </h2>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#adabelief/2" translate="no">adabelief(learning_rate \\ 0.001, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adabelief optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#adagrad/2" translate="no">adagrad(learning_rate \\ 0.001, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adagrad optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#adam/2" translate="no">adam(learning_rate \\ 0.001, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adam optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#adamw/2" translate="no">adamw(learning_rate \\ 0.001, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Adam with weight decay optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#lamb/2" translate="no">lamb(learning_rate \\ 0.01, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Lamb optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#noisy_sgd/2" translate="no">noisy_sgd(learning_rate \\ 0.01, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Noisy SGD optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#radam/2" translate="no">radam(learning_rate \\ 0.001, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Rectified Adam optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#rmsprop/2" translate="no">rmsprop(learning_rate \\ 0.01, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>RMSProp optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#sgd/2" translate="no">sgd(learning_rate \\ 0.01, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>SGD optimizer.</p></div>

    </div>

    <div class="summary-row">
      <div class="summary-signature">
        <a href="#yogi/2" translate="no">yogi(learning_rate \\ 0.01, opts \\ [])</a>

      </div>

        <div class="summary-synopsis"><p>Yogi optimizer.</p></div>

    </div>

</div>

  </section>


  <section id="functions" class="details-list">
    <h1 class="section-heading">
      <a class="hover-link" href="#functions">
        <i class="ri-link-m" aria-hidden="true"></i>
        <span class="sr-only">Link to this section</span>
      </a>
Functions
    </h1>
    <div class="functions-list">
<section class="detail" id="adabelief/2">

    <span id="adabelief/0"></span>

    <span id="adabelief/1"></span>

  <div class="detail-header">
    <a href="#adabelief/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">adabelief(learning_rate \\ 0.001, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L72" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adabelief optimizer.</p><h2 id="adabelief/2-options" class="section-heading">
  <a href="#adabelief/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:b1</code> - first moment decay. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:b2</code> - second moment decay. Defaults to <code class="inline">0.999</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:eps_root</code> - numerical stability term. Defaults to <code class="inline">1.0e-16</code></li></ul><h2 id="adabelief/2-references" class="section-heading">
  <a href="#adabelief/2-references" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">references</p>
  </a>
  References
</h2>
<ul><li><a href="https://arxiv.org/abs/2010.07468">AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients</a></li></ul>
  </section>
</section>
<section class="detail" id="adagrad/2">

    <span id="adagrad/0"></span>

    <span id="adagrad/1"></span>

  <div class="detail-header">
    <a href="#adagrad/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">adagrad(learning_rate \\ 0.001, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L88" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adagrad optimizer.</p><h2 id="adagrad/2-options" class="section-heading">
  <a href="#adagrad/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-7</code></li></ul><h2 id="adagrad/2-references" class="section-heading">
  <a href="#adagrad/2-references" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">references</p>
  </a>
  References
</h2>
<ul><li><a href="https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</a></li></ul>
  </section>
</section>
<section class="detail" id="adam/2">

    <span id="adam/0"></span>

    <span id="adam/1"></span>

  <div class="detail-header">
    <a href="#adam/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">adam(learning_rate \\ 0.001, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L107" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adam optimizer.</p><h2 id="adam/2-options" class="section-heading">
  <a href="#adam/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:b1</code> - first moment decay. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:b2</code> - second moment decay. Defaults to <code class="inline">0.999</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-8</code></li><li><code class="inline">:eps_root</code> - numerical stability term. Defaults to <code class="inline">1.0e-15</code></li></ul><h2 id="adam/2-references" class="section-heading">
  <a href="#adam/2-references" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">references</p>
  </a>
  References
</h2>
<ul><li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a></li></ul>
  </section>
</section>
<section class="detail" id="adamw/2">

    <span id="adamw/0"></span>

    <span id="adamw/1"></span>

  <div class="detail-header">
    <a href="#adamw/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">adamw(learning_rate \\ 0.001, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L123" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Adam with weight decay optimizer.</p><h2 id="adamw/2-options" class="section-heading">
  <a href="#adamw/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:b1</code> - first moment decay. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:b2</code> - second moment decay. Defaults to <code class="inline">0.999</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-8</code></li><li><code class="inline">:eps_root</code> - numerical stability term. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:decay</code> - weight decay. Defaults to <code class="inline">0.0</code></li></ul>
  </section>
</section>
<section class="detail" id="lamb/2">

    <span id="lamb/0"></span>

    <span id="lamb/1"></span>

  <div class="detail-header">
    <a href="#lamb/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">lamb(learning_rate \\ 0.01, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L147" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Lamb optimizer.</p><h2 id="lamb/2-options" class="section-heading">
  <a href="#lamb/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:b1</code> - first moment decay. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:b2</code> - second moment decay. Defaults to <code class="inline">0.999</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-8</code></li><li><code class="inline">:eps_root</code> - numerical stability term. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:decay</code> - weight decay. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:min_norm</code> - minimum norm value. Defaults to <code class="inline">0.0</code></li></ul><h2 id="lamb/2-references" class="section-heading">
  <a href="#lamb/2-references" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">references</p>
  </a>
  References
</h2>
<ul><li><a href="https://arxiv.org/abs/1904.00962">Large Batch Optimization for Deep Learning: Training BERT in 76 minutes</a></li></ul>
  </section>
</section>
<section class="detail" id="noisy_sgd/2">

    <span id="noisy_sgd/0"></span>

    <span id="noisy_sgd/1"></span>

  <div class="detail-header">
    <a href="#noisy_sgd/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">noisy_sgd(learning_rate \\ 0.01, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L165" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Noisy SGD optimizer.</p><h2 id="noisy_sgd/2-options" class="section-heading">
  <a href="#noisy_sgd/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:eta</code> - used to compute variance of noise distribution. Defaults to <code class="inline">0.1</code></li><li><code class="inline">:gamma</code> - used to compute variance of noise distribution. Defaults to <code class="inline">0.55</code></li></ul>
  </section>
</section>
<section class="detail" id="radam/2">

    <span id="radam/0"></span>

    <span id="radam/1"></span>

  <div class="detail-header">
    <a href="#radam/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">radam(learning_rate \\ 0.001, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L185" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Rectified Adam optimizer.</p><h2 id="radam/2-options" class="section-heading">
  <a href="#radam/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:b1</code> - first moment decay. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:b2</code> - second moment decay. Defaults to <code class="inline">0.999</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-8</code></li><li><code class="inline">:eps_root</code> - numerical stability term. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:threshold</code> - threshold term. Defaults to <code class="inline">5.0</code></li></ul><h2 id="radam/2-references" class="section-heading">
  <a href="#radam/2-references" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">references</p>
  </a>
  References
</h2>
<ul><li><a href="https://arxiv.org/pdf/1908.03265.pdf">On the Variance of Adaptive Learning Rate and Beyond</a></li></ul>
  </section>
</section>
<section class="detail" id="rmsprop/2">

    <span id="rmsprop/0"></span>

    <span id="rmsprop/1"></span>

  <div class="detail-header">
    <a href="#rmsprop/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">rmsprop(learning_rate \\ 0.01, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L203" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>RMSProp optimizer.</p><h2 id="rmsprop/2-options" class="section-heading">
  <a href="#rmsprop/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:centered</code> - whether to scale by centered root of EMA of squares. Defaults to <code class="inline">false</code></li><li><code class="inline">:momentum</code> - momentum term. If set, uses SGD with momentum and decay set
to value of this term.</li><li><code class="inline">:nesterov</code> - whether or not to use nesterov momentum. Defaults to <code class="inline">false</code></li><li><code class="inline">:initial_scale</code> - initial value of EMA. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:decay</code> - EMA decay rate. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-8</code></li></ul>
  </section>
</section>
<section class="detail" id="sgd/2">

    <span id="sgd/0"></span>

    <span id="sgd/1"></span>

  <div class="detail-header">
    <a href="#sgd/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">sgd(learning_rate \\ 0.01, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L230" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>SGD optimizer.</p><h2 id="sgd/2-options" class="section-heading">
  <a href="#sgd/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:momentum</code> - momentum term. If set, uses SGD with momentum and decay set
to value of this term.</li><li><code class="inline">:nesterov</code> - whether or not to use nesterov momentum. Defaults to <code class="inline">false</code></li></ul>
  </section>
</section>
<section class="detail" id="yogi/2">

    <span id="yogi/0"></span>

    <span id="yogi/1"></span>

  <div class="detail-header">
    <a href="#yogi/2" class="detail-link" title="Link to this function">
      <i class="ri-link-m" aria-hidden="true"></i>
      <span class="sr-only">Link to this function</span>
    </a>
    <h1 class="signature" translate="no">yogi(learning_rate \\ 0.01, opts \\ [])</h1>

      <a href="https://github.com/elixir-nx/axon/blob/v0.3.0/lib/axon/optimizers.ex#L257" class="icon-action" rel="help" title="View Source">
       <i class="ri-code-s-slash-line" aria-hidden="true"></i>
       <span class="sr-only">View Source</span>
     </a>


  </div>

  <section class="docstring">

<p>Yogi optimizer.</p><h2 id="yogi/2-options" class="section-heading">
  <a href="#yogi/2-options" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">options</p>
  </a>
  Options
</h2>
<ul><li><code class="inline">:initial_accumulator_value</code> - initial value for first and second moment. Defaults to <code class="inline">0.0</code></li><li><code class="inline">:b1</code> - first moment decay. Defaults to <code class="inline">0.9</code></li><li><code class="inline">:b2</code> - second moment decay. Defaults to <code class="inline">0.999</code></li><li><code class="inline">:eps</code> - numerical stability term. Defaults to <code class="inline">1.0e-8</code></li><li><code class="inline">:eps_root</code> - numerical stability term. Defaults to <code class="inline">0.0</code></li></ul><h2 id="yogi/2-references" class="section-heading">
  <a href="#yogi/2-references" class="hover-link"><i class="ri-link-m" aria-hidden="true"></i>
  <p class="sr-only">references</p>
  </a>
  References
</h2>
<ul><li><a href="https://papers.nips.cc/paper/2018/file/90365351ccc7437a1309dc64e4db32a3-Paper.pdf">Adaptive Methods for Nonconvex Optimization</a></li></ul>
  </section>
</section>

    </div>
  </section>

      <footer class="footer">
        <p>

            <span class="line">
              <a href="https://hex.pm/packages/axon/0.3.0" class="footer-hex-package">Hex Package</a>

              <a href="https://preview.hex.pm/preview/axon/0.3.0">Hex Preview</a>

                (<a href="https://preview.hex.pm/preview/axon/0.3.0/show/lib/axon/optimizers.ex">current file</a>)

            </span>

          <span class="line">
            <button class="a-main footer-button display-quick-switch" title="Search HexDocs packages">
              Search HexDocs
            </button>

              <a href="Axon.epub" title="ePub version">
                Download ePub version
              </a>

          </span>
        </p>

        <p class="built-using">
          Built using
          <a href="https://github.com/elixir-lang/ex_doc" title="ExDoc" target="_blank" rel="help noopener" translate="no">ExDoc</a> (v0.29.1) for the

            <a href="https://elixir-lang.org" title="Elixir" target="_blank" translate="no">Elixir programming language</a>

        </p>
      </footer>
    </div>
  </div>
</section>
</div>

<!-- Render math with KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha384-t5CR+zwDAROtph0PXGte6ia8heboACF9R5l/DiY+WZ3P2lxNgvJkQk5n7GPvLMYw" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js" integrity="sha384-FaFLTlohFghEIZkw6VGwmf9ISTubWAVYW8tG8+w2LAIftJEULZABrF9PPFv+tVkH" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js" integrity="sha384-bHBqxz8fokvgoJ/sc17HODNxa42TlaEhB+w8ZJXTc2nZf1VgEaFZeZvT4Mznfz0v" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
      ]
    });
  });
</script>

<!-- Render diagrams with Mermaid -->
<script src="https://cdn.jsdelivr.net/npm/mermaid@8.13.3/dist/mermaid.min.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    mermaid.initialize({ startOnLoad: false });
    let id = 0;
    for (const codeEl of document.querySelectorAll("pre code.mermaid")) {
      const preEl = codeEl.parentElement;
      const graphDefinition = codeEl.textContent;
      const graphEl = document.createElement("div");
      const graphId = "mermaid-graph-" + id++;
      mermaid.render(graphId, graphDefinition, function (svgSource, bindListeners) {
        graphEl.innerHTML = svgSource;
        bindListeners && bindListeners(graphEl);
        preEl.insertAdjacentElement("afterend", graphEl);
        preEl.remove();
      });
    }
  });
</script>

  </body>
</html>
